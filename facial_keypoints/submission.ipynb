{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdLookupTable.csv    test.csv             training.csv\r\n",
      "SampleSubmission.csv test.zip             training.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/facial-keypoints-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET_PATH = 'data/facial-keypoints-detection/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>182 183 182 182 180 180 176 169 156 137 124 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>177 176 174 170 169 169 168 166 166 166 161 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>176 174 174 175 174 174 176 176 175 171 165 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50 47 44 101 144 149 120 58 48 42 35 35 37 39 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId                                              Image\n",
       "0        1  182 183 182 182 180 180 176 169 156 137 124 10...\n",
       "1        2  76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...\n",
       "2        3  177 176 174 170 169 169 168 166 166 166 161 14...\n",
       "3        4  176 174 174 175 174 174 176 176 175 171 165 15...\n",
       "4        5  50 47 44 101 144 149 120 58 48 42 35 35 37 39 ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(TEST_DATASET_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make torch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self, image: np.ndarray, idx: int):\n",
    "        assert isinstance(image, np.ndarray), f\"Invalid image: {type(image)}\"\n",
    "        assert image.shape == Sample.image_shape(), f\"Invalid shape: {image.shape}\"\n",
    "        assert image.dtype == np.uint8, f\"Invalid dtype: {image.dtype}\"\n",
    "        self._img = image\n",
    "        self._idx = idx\n",
    "        \n",
    "    @staticmethod\n",
    "    def keypoints_names():\n",
    "        return {\n",
    "            'left_eye_center', 'right_eye_center',\n",
    "            'left_eye_inner_corner', 'left_eye_outer_corner',\n",
    "            'right_eye_inner_corner', 'right_eye_outer_corner',\n",
    "            'left_eyebrow_inner_end', 'left_eyebrow_outer_end',\n",
    "            'right_eyebrow_inner_end', 'right_eyebrow_outer_end',\n",
    "            'nose_tip', 'mouth_left_corner', 'mouth_right_corner',\n",
    "            'mouth_center_top_lip', 'mouth_center_bottom_lip',\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def image_shape():\n",
    "        return (96, 96, 3)\n",
    "\n",
    "    @staticmethod\n",
    "    def image_from_str(s):\n",
    "        flatten_array = np.asarray(list(map(int, s.split(' '))))\n",
    "        image = flatten_array.reshape(Sample.image_shape()[:2])\n",
    "        image = np.repeat(np.expand_dims(image, -1), 3, -1)\n",
    "        return image.astype(np.uint8)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_series(series, hint=None):\n",
    "        image = Sample.image_from_str(series[\"Image\"])\n",
    "        idx = series[\"ImageId\"]\n",
    "        return Sample(\n",
    "            image=image,\n",
    "            idx=idx,\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def image(self):\n",
    "        return self._img\n",
    "\n",
    "    @property\n",
    "    def idx(self):\n",
    "        return self._idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class KeyPointsDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self._df = pd.read_csv(csv_file).dropna()\n",
    "        self._transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data_sample = Sample.from_series(self._df.iloc[idx])\n",
    "        sample = {\n",
    "            'image': data_sample.image,\n",
    "            'idx': data_sample.idx\n",
    "        }\n",
    "\n",
    "        if self._transform:\n",
    "            sample = self._transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, idx = sample['image'], sample['idx']\n",
    "        return {\n",
    "            'image': torch.from_numpy(image).float(),\n",
    "            'idx': torch.from_numpy(np.asarray(idx)).int(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KeyPointsDataset(TEST_DATASET_PATH, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 96, 96, 3]),\n",
       " torch.float32,\n",
       " tensor([1070, 1281, 1591, 1332, 1583, 1408,  480, 1759,  184,  164, 1178,  740,\n",
       "         1589,  269, 1294, 1313], dtype=torch.int32))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(dataloader)\n",
    "batch = next(it)\n",
    "imgs_batch, idx_batch = batch['image'], batch['idx']\n",
    "imgs_batch.shape, imgs_batch.dtype, idx_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iolkhovsky/Documents/repos/kaggle_sandbox/facial_keypoints/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KeypointsRegressor(\n",
       "  (preprocessor): Preprocessor(\n",
       "    (_normalize): Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "  )\n",
       "  (core): ModelCore(\n",
       "    (backbone): MobileNetV2(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (9): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (10): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (11): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (12): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (13): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (14): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (15): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (16): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (17): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (18): Conv2dNormActivation(\n",
       "          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): Sequential(\n",
       "        (0): Dropout(p=0.2, inplace=False)\n",
       "        (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (regression_head): RegressionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): MLPLayer(\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dense): Linear(in_features=1000, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): MLPLayer(\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (dense): Linear(in_features=128, out_features=30, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (postprocessor): Postprocessor()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from model.keypoints_regressor import build_model\n",
    "\n",
    "\n",
    "deploy_config = 'configs/deploy.yaml'\n",
    "checkpoint = 'checkpoints/26-Nov-2022-13-50-01/state_dict_epoch_99_final'\n",
    "\n",
    "with open(deploy_config, 'rt') as f:\n",
    "    config = yaml.safe_load(f.read())\n",
    "model = build_model(config)\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iolkhovsky/Documents/repos/kaggle_sandbox/facial_keypoints/venv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[35.3043, 63.6925, 36.2361, 57.3584, 71.3809, 61.1587, 67.9841, 46.4500,\n",
       "         36.7024, 22.8989, 28.9271, 76.8702, 35.9782, 29.3494, 28.0546, 37.0407,\n",
       "         78.5478, 46.8620, 71.6979, 33.5923, 56.4348, 44.3751, 36.7381, 35.3563,\n",
       "         27.7292, 53.2309, 29.1551, 16.4275, 35.8894, 70.2847],\n",
       "        [38.1928, 63.0361, 39.3858, 55.8437, 76.4693, 61.0526, 76.5677, 45.3471,\n",
       "         38.7263, 20.2209, 32.1163, 77.0672, 38.0382, 27.9887, 31.9161, 38.0139,\n",
       "         80.2802, 45.5125, 76.0491, 29.5341, 60.1795, 45.3648, 39.3476, 35.4728,\n",
       "         32.1306, 53.9716, 31.3090, 14.4804, 38.9390, 70.9580],\n",
       "        [39.3644, 64.5978, 40.2081, 57.3690, 76.3040, 61.0421, 75.8854, 45.4584,\n",
       "         37.4304, 23.0431, 34.6551, 79.1130, 37.3073, 30.7761, 31.9817, 41.0296,\n",
       "         79.7447, 45.3106, 73.8315, 29.4848, 61.4714, 46.3289, 39.1072, 38.0739,\n",
       "         33.1281, 55.7794, 30.0678, 17.9651, 40.6153, 72.5675],\n",
       "        [40.4780, 65.8592, 39.8696, 58.6680, 74.0926, 56.6729, 67.7126, 42.4591,\n",
       "         32.5308, 23.3074, 37.4755, 80.4841, 33.3014, 31.1051, 27.9273, 41.6045,\n",
       "         76.5531, 40.7888, 67.8355, 26.4147, 54.0098, 45.4773, 35.7010, 37.7533,\n",
       "         31.5083, 58.0741, 23.8618, 18.4240, 43.0285, 72.8246],\n",
       "        [34.6416, 64.5335, 36.1500, 56.5786, 70.8700, 65.5423, 69.4739, 46.4346,\n",
       "         37.9425, 20.9349, 27.1501, 78.7850, 36.7314, 28.4469, 28.0589, 35.0376,\n",
       "         77.3826, 47.1802, 71.5037, 31.5612, 53.2920, 41.9311, 37.4849, 35.3029,\n",
       "         26.6879, 52.4966, 29.3366, 14.8705, 35.0503, 72.5059],\n",
       "        [38.6041, 60.8383, 39.2347, 54.9413, 73.2276, 57.3064, 71.8368, 44.3004,\n",
       "         37.5640, 22.2463, 32.3097, 73.1302, 37.3744, 29.0649, 30.7228, 39.3979,\n",
       "         78.8936, 44.3049, 71.8474, 27.9822, 59.4770, 47.7764, 38.6909, 35.5505,\n",
       "         32.1106, 54.4222, 29.9768, 17.1122, 39.4047, 67.0677],\n",
       "        [36.6577, 64.2565, 38.6551, 56.3313, 68.6497, 68.7612, 70.7093, 49.1089,\n",
       "         43.5561, 19.5149, 28.6316, 77.9350, 41.7755, 27.6402, 32.5492, 35.1071,\n",
       "         81.4210, 50.6460, 72.3913, 30.7367, 59.4324, 46.0018, 41.7386, 34.9572,\n",
       "         29.9906, 52.8544, 36.5521, 12.9063, 36.6060, 72.2880],\n",
       "        [34.9217, 64.5999, 35.9919, 58.7285, 72.0632, 63.6053, 67.5201, 49.4379,\n",
       "         39.3731, 22.7777, 26.5562, 76.2844, 38.1276, 28.5334, 29.7811, 36.0205,\n",
       "         81.0885, 50.6931, 74.0399, 35.8741, 53.4821, 47.8680, 38.2082, 34.6065,\n",
       "         28.4725, 55.8966, 31.6268, 16.1782, 35.0222, 70.6086],\n",
       "        [38.3272, 65.9250, 38.8633, 59.1118, 77.9192, 63.0562, 69.7856, 46.9689,\n",
       "         38.3760, 20.5173, 31.3847, 81.0535, 37.4092, 27.6309, 26.2857, 38.7206,\n",
       "         87.9882, 46.3472, 76.9890, 29.3502, 54.5846, 47.0213, 38.2444, 34.4056,\n",
       "         26.3716, 56.9172, 29.6017, 13.5088, 39.6461, 73.0042],\n",
       "        [37.7721, 64.3191, 39.2879, 56.8927, 81.7992, 63.9427, 80.1049, 47.4651,\n",
       "         41.3158, 17.3535, 30.3515, 79.6413, 39.7300, 25.3970, 31.6193, 36.7480,\n",
       "         88.3619, 47.7111, 83.3963, 30.3383, 61.1486, 47.0646, 40.4865, 33.4300,\n",
       "         30.8803, 54.1559, 33.8422, 10.1183, 38.3540, 72.7982],\n",
       "        [33.5224, 61.4020, 36.3077, 54.8640, 67.9175, 67.9925, 70.3231, 52.9867,\n",
       "         43.8946, 21.5503, 23.5339, 73.0492, 41.5204, 28.4984, 32.5260, 35.9914,\n",
       "         77.2635, 54.4718, 74.1930, 37.3405, 57.0353, 50.3738, 41.0720, 35.6865,\n",
       "         29.6037, 52.0612, 37.7039, 14.5870, 32.2621, 68.6864],\n",
       "        [37.4454, 61.3055, 38.5751, 54.9028, 71.7169, 59.2591, 72.6104, 45.4442,\n",
       "         38.1332, 20.5721, 30.4992, 74.2070, 37.5858, 28.2021, 30.7433, 38.7205,\n",
       "         78.3963, 45.4719, 71.8664, 28.2575, 61.0602, 48.5860, 38.7320, 35.3187,\n",
       "         31.7825, 54.1906, 30.4798, 14.8311, 37.9183, 68.2945],\n",
       "        [34.3287, 60.1982, 37.7644, 52.8181, 72.9826, 69.8412, 76.6301, 52.1671,\n",
       "         48.3273, 20.1883, 23.8383, 71.4929, 45.2781, 26.8243, 36.5352, 31.2297,\n",
       "         78.7109, 54.4260, 80.9779, 40.6912, 59.2550, 42.3462, 44.3681, 33.6874,\n",
       "         31.0348, 46.6017, 41.5665, 13.4067, 32.7900, 68.3831],\n",
       "        [36.4889, 64.2332, 37.3880, 57.6696, 74.6857, 62.1444, 68.8543, 46.9055,\n",
       "         39.6378, 20.7153, 28.1175, 77.3296, 38.2661, 27.1332, 28.1586, 35.2742,\n",
       "         80.4431, 47.7999, 75.8939, 32.7622, 50.7180, 44.8663, 38.5755, 33.5968,\n",
       "         27.7298, 54.6727, 30.7163, 14.0663, 37.1303, 70.9390],\n",
       "        [32.2942, 62.7097, 34.5956, 54.9601, 68.4103, 66.0535, 69.8843, 49.6212,\n",
       "         39.6501, 20.6928, 24.1009, 76.3467, 37.8797, 28.5093, 29.9461, 35.0702,\n",
       "         75.6283, 50.4614, 72.1530, 36.8125, 58.0295, 44.1088, 37.9874, 35.4242,\n",
       "         27.4582, 49.2239, 32.6113, 13.4481, 31.7311, 70.9546],\n",
       "        [36.4386, 62.1966, 37.8615, 55.6717, 71.9386, 62.2052, 70.7868, 46.3480,\n",
       "         39.6742, 21.9324, 29.2195, 74.7601, 38.8455, 28.0905, 32.0010, 34.4436,\n",
       "         78.8548, 47.1983, 73.1566, 33.0845, 57.7953, 42.6541, 39.4016, 34.2873,\n",
       "         30.6713, 51.9497, 32.1940, 15.9137, 36.5436, 69.0337]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(imgs_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'left_eye_center': (35.304344, 63.692497),\n",
       "  'right_eye_center': (36.236076, 57.358444),\n",
       "  'left_eye_inner_corner': (71.38088, 61.15867),\n",
       "  'left_eye_outer_corner': (67.984116, 46.449974),\n",
       "  'right_eye_inner_corner': (36.702362, 22.898897),\n",
       "  'right_eye_outer_corner': (28.927053, 76.870186),\n",
       "  'left_eyebrow_inner_end': (35.978218, 29.349426),\n",
       "  'left_eyebrow_outer_end': (28.054579, 37.04071),\n",
       "  'right_eyebrow_inner_end': (78.547775, 46.86204),\n",
       "  'right_eyebrow_outer_end': (71.69785, 33.592274),\n",
       "  'nose_tip': (56.43479, 44.375122),\n",
       "  'mouth_left_corner': (36.73812, 35.356277),\n",
       "  'mouth_right_corner': (27.729233, 53.23085),\n",
       "  'mouth_center_top_lip': (29.155083, 16.427452),\n",
       "  'mouth_center_bottom_lip': (35.889435, 70.28465)},\n",
       " {'left_eye_center': (38.192787, 63.03613),\n",
       "  'right_eye_center': (39.38582, 55.84365),\n",
       "  'left_eye_inner_corner': (76.469315, 61.05259),\n",
       "  'left_eye_outer_corner': (76.56773, 45.347073),\n",
       "  'right_eye_inner_corner': (38.726273, 20.220913),\n",
       "  'right_eye_outer_corner': (32.116272, 77.06722),\n",
       "  'left_eyebrow_inner_end': (38.038185, 27.988707),\n",
       "  'left_eyebrow_outer_end': (31.916069, 38.013912),\n",
       "  'right_eyebrow_inner_end': (80.280174, 45.51247),\n",
       "  'right_eyebrow_outer_end': (76.04907, 29.534054),\n",
       "  'nose_tip': (60.179543, 45.364815),\n",
       "  'mouth_left_corner': (39.34762, 35.47277),\n",
       "  'mouth_right_corner': (32.130608, 53.971603),\n",
       "  'mouth_center_top_lip': (31.309036, 14.480415),\n",
       "  'mouth_center_bottom_lip': (38.939, 70.95802)},\n",
       " {'left_eye_center': (39.36436, 64.597824),\n",
       "  'right_eye_center': (40.208054, 57.369026),\n",
       "  'left_eye_inner_corner': (76.30404, 61.04211),\n",
       "  'left_eye_outer_corner': (75.88538, 45.458393),\n",
       "  'right_eye_inner_corner': (37.43038, 23.043142),\n",
       "  'right_eye_outer_corner': (34.655064, 79.11297),\n",
       "  'left_eyebrow_inner_end': (37.307312, 30.776123),\n",
       "  'left_eyebrow_outer_end': (31.98169, 41.029617),\n",
       "  'right_eyebrow_inner_end': (79.7447, 45.31065),\n",
       "  'right_eyebrow_outer_end': (73.83145, 29.484781),\n",
       "  'nose_tip': (61.47136, 46.3289),\n",
       "  'mouth_left_corner': (39.10715, 38.073887),\n",
       "  'mouth_right_corner': (33.12812, 55.77945),\n",
       "  'mouth_center_top_lip': (30.067823, 17.965061),\n",
       "  'mouth_center_bottom_lip': (40.615257, 72.56745)},\n",
       " {'left_eye_center': (40.47798, 65.85915),\n",
       "  'right_eye_center': (39.869576, 58.667976),\n",
       "  'left_eye_inner_corner': (74.09256, 56.672897),\n",
       "  'left_eye_outer_corner': (67.71263, 42.459084),\n",
       "  'right_eye_inner_corner': (32.530823, 23.307434),\n",
       "  'right_eye_outer_corner': (37.47548, 80.48412),\n",
       "  'left_eyebrow_inner_end': (33.301434, 31.105057),\n",
       "  'left_eyebrow_outer_end': (27.927273, 41.604546),\n",
       "  'right_eyebrow_inner_end': (76.55311, 40.78876),\n",
       "  'right_eyebrow_outer_end': (67.83547, 26.414665),\n",
       "  'nose_tip': (54.009766, 45.47733),\n",
       "  'mouth_left_corner': (35.70102, 37.753296),\n",
       "  'mouth_right_corner': (31.508255, 58.074066),\n",
       "  'mouth_center_top_lip': (23.861801, 18.424046),\n",
       "  'mouth_center_bottom_lip': (43.028473, 72.82458)},\n",
       " {'left_eye_center': (34.641552, 64.53348),\n",
       "  'right_eye_center': (36.149967, 56.57859),\n",
       "  'left_eye_inner_corner': (70.86997, 65.54233),\n",
       "  'left_eye_outer_corner': (69.47386, 46.434628),\n",
       "  'right_eye_inner_corner': (37.942482, 20.934927),\n",
       "  'right_eye_outer_corner': (27.150078, 78.78497),\n",
       "  'left_eyebrow_inner_end': (36.731422, 28.446903),\n",
       "  'left_eyebrow_outer_end': (28.058893, 35.037582),\n",
       "  'right_eyebrow_inner_end': (77.3826, 47.180195),\n",
       "  'right_eyebrow_outer_end': (71.50373, 31.561174),\n",
       "  'nose_tip': (53.29197, 41.931107),\n",
       "  'mouth_left_corner': (37.48494, 35.302933),\n",
       "  'mouth_right_corner': (26.68789, 52.496613),\n",
       "  'mouth_center_top_lip': (29.336597, 14.87047),\n",
       "  'mouth_center_bottom_lip': (35.05027, 72.50586)},\n",
       " {'left_eye_center': (38.604084, 60.838257),\n",
       "  'right_eye_center': (39.234734, 54.941277),\n",
       "  'left_eye_inner_corner': (73.227646, 57.306393),\n",
       "  'left_eye_outer_corner': (71.83684, 44.300392),\n",
       "  'right_eye_inner_corner': (37.564, 22.246304),\n",
       "  'right_eye_outer_corner': (32.30969, 73.13018),\n",
       "  'left_eyebrow_inner_end': (37.374386, 29.06493),\n",
       "  'left_eyebrow_outer_end': (30.722755, 39.397873),\n",
       "  'right_eyebrow_inner_end': (78.89357, 44.304916),\n",
       "  'right_eyebrow_outer_end': (71.84737, 27.982197),\n",
       "  'nose_tip': (59.476994, 47.77644),\n",
       "  'mouth_left_corner': (38.690918, 35.55052),\n",
       "  'mouth_right_corner': (32.110603, 54.422184),\n",
       "  'mouth_center_top_lip': (29.976768, 17.11216),\n",
       "  'mouth_center_bottom_lip': (39.404747, 67.06775)},\n",
       " {'left_eye_center': (36.65766, 64.25653),\n",
       "  'right_eye_center': (38.655094, 56.33131),\n",
       "  'left_eye_inner_corner': (68.649734, 68.761246),\n",
       "  'left_eye_outer_corner': (70.70926, 49.108932),\n",
       "  'right_eye_inner_corner': (43.556107, 19.514854),\n",
       "  'right_eye_outer_corner': (28.631615, 77.93502),\n",
       "  'left_eyebrow_inner_end': (41.77545, 27.640177),\n",
       "  'left_eyebrow_outer_end': (32.549232, 35.107113),\n",
       "  'right_eyebrow_inner_end': (81.421005, 50.64595),\n",
       "  'right_eyebrow_outer_end': (72.39134, 30.73674),\n",
       "  'nose_tip': (59.43243, 46.001804),\n",
       "  'mouth_left_corner': (41.738583, 34.957203),\n",
       "  'mouth_right_corner': (29.990555, 52.8544),\n",
       "  'mouth_center_top_lip': (36.552128, 12.906275),\n",
       "  'mouth_center_bottom_lip': (36.606007, 72.288025)},\n",
       " {'left_eye_center': (34.92175, 64.59993),\n",
       "  'right_eye_center': (35.991882, 58.728493),\n",
       "  'left_eye_inner_corner': (72.06316, 63.60533),\n",
       "  'left_eye_outer_corner': (67.52005, 49.437904),\n",
       "  'right_eye_inner_corner': (39.3731, 22.777727),\n",
       "  'right_eye_outer_corner': (26.556206, 76.28438),\n",
       "  'left_eyebrow_inner_end': (38.127632, 28.53341),\n",
       "  'left_eyebrow_outer_end': (29.781075, 36.020546),\n",
       "  'right_eyebrow_inner_end': (81.088524, 50.69315),\n",
       "  'right_eyebrow_outer_end': (74.03987, 35.87406),\n",
       "  'nose_tip': (53.482056, 47.868034),\n",
       "  'mouth_left_corner': (38.20824, 34.60646),\n",
       "  'mouth_right_corner': (28.472538, 55.896637),\n",
       "  'mouth_center_top_lip': (31.626778, 16.178185),\n",
       "  'mouth_center_bottom_lip': (35.02221, 70.6086)},\n",
       " {'left_eye_center': (38.327217, 65.92502),\n",
       "  'right_eye_center': (38.863262, 59.111847),\n",
       "  'left_eye_inner_corner': (77.91918, 63.056152),\n",
       "  'left_eye_outer_corner': (69.7856, 46.96888),\n",
       "  'right_eye_inner_corner': (38.375984, 20.51735),\n",
       "  'right_eye_outer_corner': (31.38467, 81.05353),\n",
       "  'left_eyebrow_inner_end': (37.409237, 27.630886),\n",
       "  'left_eyebrow_outer_end': (26.285706, 38.72063),\n",
       "  'right_eyebrow_inner_end': (87.98819, 46.347183),\n",
       "  'right_eyebrow_outer_end': (76.98903, 29.350246),\n",
       "  'nose_tip': (54.584557, 47.0213),\n",
       "  'mouth_left_corner': (38.244434, 34.405617),\n",
       "  'mouth_right_corner': (26.37162, 56.917175),\n",
       "  'mouth_center_top_lip': (29.601727, 13.508753),\n",
       "  'mouth_center_bottom_lip': (39.646114, 73.00418)},\n",
       " {'left_eye_center': (37.772125, 64.31911),\n",
       "  'right_eye_center': (39.287937, 56.892677),\n",
       "  'left_eye_inner_corner': (81.79917, 63.942657),\n",
       "  'left_eye_outer_corner': (80.10492, 47.465145),\n",
       "  'right_eye_inner_corner': (41.315792, 17.353462),\n",
       "  'right_eye_outer_corner': (30.351522, 79.6413),\n",
       "  'left_eyebrow_inner_end': (39.730003, 25.396975),\n",
       "  'left_eyebrow_outer_end': (31.619253, 36.747955),\n",
       "  'right_eyebrow_inner_end': (88.36189, 47.711124),\n",
       "  'right_eyebrow_outer_end': (83.39633, 30.338306),\n",
       "  'nose_tip': (61.148605, 47.064648),\n",
       "  'mouth_left_corner': (40.48649, 33.42996),\n",
       "  'mouth_right_corner': (30.880285, 54.15595),\n",
       "  'mouth_center_top_lip': (33.84217, 10.118345),\n",
       "  'mouth_center_bottom_lip': (38.354004, 72.798225)},\n",
       " {'left_eye_center': (33.522396, 61.401985),\n",
       "  'right_eye_center': (36.30774, 54.863976),\n",
       "  'left_eye_inner_corner': (67.91753, 67.99249),\n",
       "  'left_eye_outer_corner': (70.32314, 52.98673),\n",
       "  'right_eye_inner_corner': (43.894646, 21.550344),\n",
       "  'right_eye_outer_corner': (23.533878, 73.04916),\n",
       "  'left_eyebrow_inner_end': (41.52041, 28.49836),\n",
       "  'left_eyebrow_outer_end': (32.52599, 35.991447),\n",
       "  'right_eyebrow_inner_end': (77.263535, 54.471817),\n",
       "  'right_eyebrow_outer_end': (74.19302, 37.34053),\n",
       "  'nose_tip': (57.035263, 50.373768),\n",
       "  'mouth_left_corner': (41.07202, 35.686527),\n",
       "  'mouth_right_corner': (29.603668, 52.06122),\n",
       "  'mouth_center_top_lip': (37.703945, 14.5870075),\n",
       "  'mouth_center_bottom_lip': (32.26214, 68.68643)},\n",
       " {'left_eye_center': (37.44544, 61.30555),\n",
       "  'right_eye_center': (38.575138, 54.902786),\n",
       "  'left_eye_inner_corner': (71.71686, 59.259056),\n",
       "  'left_eye_outer_corner': (72.6104, 45.444195),\n",
       "  'right_eye_inner_corner': (38.13318, 20.572126),\n",
       "  'right_eye_outer_corner': (30.499214, 74.206955),\n",
       "  'left_eyebrow_inner_end': (37.585823, 28.202093),\n",
       "  'left_eyebrow_outer_end': (30.743345, 38.720524),\n",
       "  'right_eyebrow_inner_end': (78.396255, 45.471897),\n",
       "  'right_eyebrow_outer_end': (71.86644, 28.257492),\n",
       "  'nose_tip': (61.060234, 48.585983),\n",
       "  'mouth_left_corner': (38.73197, 35.318726),\n",
       "  'mouth_right_corner': (31.782492, 54.190582),\n",
       "  'mouth_center_top_lip': (30.479824, 14.831145),\n",
       "  'mouth_center_bottom_lip': (37.918262, 68.294464)},\n",
       " {'left_eye_center': (34.328735, 60.198246),\n",
       "  'right_eye_center': (37.764446, 52.818108),\n",
       "  'left_eye_inner_corner': (72.98261, 69.841156),\n",
       "  'left_eye_outer_corner': (76.63015, 52.167107),\n",
       "  'right_eye_inner_corner': (48.327263, 20.18828),\n",
       "  'right_eye_outer_corner': (23.83831, 71.49289),\n",
       "  'left_eyebrow_inner_end': (45.278122, 26.824348),\n",
       "  'left_eyebrow_outer_end': (36.535175, 31.22972),\n",
       "  'right_eyebrow_inner_end': (78.71089, 54.426018),\n",
       "  'right_eyebrow_outer_end': (80.9779, 40.691208),\n",
       "  'nose_tip': (59.25495, 42.346176),\n",
       "  'mouth_left_corner': (44.368088, 33.687416),\n",
       "  'mouth_right_corner': (31.034801, 46.601715),\n",
       "  'mouth_center_top_lip': (41.566475, 13.406679),\n",
       "  'mouth_center_bottom_lip': (32.789986, 68.38313)},\n",
       " {'left_eye_center': (36.488907, 64.23323),\n",
       "  'right_eye_center': (37.387997, 57.66956),\n",
       "  'left_eye_inner_corner': (74.685715, 62.144386),\n",
       "  'left_eye_outer_corner': (68.85432, 46.905525),\n",
       "  'right_eye_inner_corner': (39.637794, 20.715298),\n",
       "  'right_eye_outer_corner': (28.117523, 77.329575),\n",
       "  'left_eyebrow_inner_end': (38.266144, 27.13324),\n",
       "  'left_eyebrow_outer_end': (28.158615, 35.274208),\n",
       "  'right_eyebrow_inner_end': (80.443054, 47.79988),\n",
       "  'right_eyebrow_outer_end': (75.89389, 32.76219),\n",
       "  'nose_tip': (50.718025, 44.866314),\n",
       "  'mouth_left_corner': (38.575523, 33.596832),\n",
       "  'mouth_right_corner': (27.729843, 54.672707),\n",
       "  'mouth_center_top_lip': (30.716316, 14.066265),\n",
       "  'mouth_center_bottom_lip': (37.130302, 70.93901)},\n",
       " {'left_eye_center': (32.294167, 62.709656),\n",
       "  'right_eye_center': (34.59555, 54.960144),\n",
       "  'left_eye_inner_corner': (68.41032, 66.05354),\n",
       "  'left_eye_outer_corner': (69.88434, 49.621223),\n",
       "  'right_eye_inner_corner': (39.650055, 20.692774),\n",
       "  'right_eye_outer_corner': (24.10086, 76.34668),\n",
       "  'left_eyebrow_inner_end': (37.879745, 28.5093),\n",
       "  'left_eyebrow_outer_end': (29.946117, 35.070152),\n",
       "  'right_eyebrow_inner_end': (75.62825, 50.461426),\n",
       "  'right_eyebrow_outer_end': (72.153046, 36.812523),\n",
       "  'nose_tip': (58.029545, 44.108772),\n",
       "  'mouth_left_corner': (37.987404, 35.424164),\n",
       "  'mouth_right_corner': (27.45817, 49.223923),\n",
       "  'mouth_center_top_lip': (32.61134, 13.448095),\n",
       "  'mouth_center_bottom_lip': (31.731117, 70.95462)},\n",
       " {'left_eye_center': (36.438637, 62.196636),\n",
       "  'right_eye_center': (37.861492, 55.67167),\n",
       "  'left_eye_inner_corner': (71.938644, 62.20522),\n",
       "  'left_eye_outer_corner': (70.78676, 46.34796),\n",
       "  'right_eye_inner_corner': (39.674168, 21.932388),\n",
       "  'right_eye_outer_corner': (29.21946, 74.76009),\n",
       "  'left_eyebrow_inner_end': (38.84545, 28.090479),\n",
       "  'left_eyebrow_outer_end': (32.000988, 34.443554),\n",
       "  'right_eyebrow_inner_end': (78.85483, 47.198338),\n",
       "  'right_eyebrow_outer_end': (73.156555, 33.084457),\n",
       "  'nose_tip': (57.795288, 42.65414),\n",
       "  'mouth_left_corner': (39.40155, 34.28725),\n",
       "  'mouth_right_corner': (30.671282, 51.949677),\n",
       "  'mouth_center_top_lip': (32.19403, 15.913681),\n",
       "  'mouth_center_bottom_lip': (36.543613, 69.03372)}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(imgs_batch, ret_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iolkhovsky/Documents/repos/kaggle_sandbox/facial_keypoints/venv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "row_idx = 0\n",
    "for batch_id, batch in enumerate(dataloader):\n",
    "    imgs_batch, idx_batch = batch['image'], batch['idx']\n",
    "    preds = model(imgs_batch, ret_raw=False)\n",
    "    for image_pred, image_idx in zip(preds, idx_batch):\n",
    "        image_idx = int(image_idx.numpy())\n",
    "        predictions[image_idx] = image_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left_eye_center': (36.18582, 66.12157),\n",
       " 'right_eye_center': (37.310413, 59.63777),\n",
       " 'left_eye_inner_corner': (76.02757, 63.668007),\n",
       " 'left_eye_outer_corner': (72.544754, 48.25981),\n",
       " 'right_eye_inner_corner': (39.38438, 20.576767),\n",
       " 'right_eye_outer_corner': (28.43425, 79.46573),\n",
       " 'left_eyebrow_inner_end': (38.20011, 27.119938),\n",
       " 'left_eyebrow_outer_end': (30.850714, 36.181896),\n",
       " 'right_eyebrow_inner_end': (85.47078, 48.87603),\n",
       " 'right_eyebrow_outer_end': (77.34552, 33.21126),\n",
       " 'nose_tip': (57.542732, 46.71447),\n",
       " 'mouth_left_corner': (38.67534, 33.900158),\n",
       " 'mouth_right_corner': (29.658188, 57.02594),\n",
       " 'mouth_center_top_lip': (31.650848, 14.025801),\n",
       " 'mouth_center_bottom_lip': (36.674168, 73.16548)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowId  Location\n",
       "0      1         0\n",
       "1      2         0\n",
       "2      3         0\n",
       "3      4         0\n",
       "4      5         0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.read_csv('data/facial-keypoints-detection/SampleSubmission.csv')\n",
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>FeatureName</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>left_eye_center_x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>left_eye_center_y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>right_eye_center_x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>right_eye_center_y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>left_eye_inner_corner_x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowId  ImageId              FeatureName  Location\n",
       "0      1        1        left_eye_center_x       NaN\n",
       "1      2        1        left_eye_center_y       NaN\n",
       "2      3        1       right_eye_center_x       NaN\n",
       "3      4        1       right_eye_center_y       NaN\n",
       "4      5        1  left_eye_inner_corner_x       NaN"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup = pd.read_csv('data/facial-keypoints-detection/IdLookupTable.csv')\n",
    "lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.460831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36.115658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>59.164566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>36.816216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>61.841137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowId   Location\n",
       "0      1  65.460831\n",
       "1      2  36.115658\n",
       "2      3  59.164566\n",
       "3      4  36.816216\n",
       "4      5  61.841137"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "data = defaultdict(list)\n",
    "for rowid in example_df[\"RowId\"]:\n",
    "    mapping = lookup.loc[lookup['RowId'] == rowid]\n",
    "    image_id = mapping['ImageId'].values[0]\n",
    "    feature_name = mapping['FeatureName'].values[0]\n",
    "    feature_name, coord = feature_name[:-2], feature_name.split(\"_\")[-1]\n",
    "    pred = predictions[image_id][feature_name]\n",
    "    location = pred[0] if coord == 'y' else pred[1]\n",
    "    data[\"RowId\"].append(rowid)\n",
    "    data[\"Location\"].append(location)\n",
    "\n",
    "ans_df = pd.DataFrame.from_dict(data)\n",
    "ans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27124"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1cd980e0717b7b74a4ca6f3ce31a2d0945cf99ccf337b76efe1e74a5ca834d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
